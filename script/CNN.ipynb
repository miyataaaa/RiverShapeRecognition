{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNNによる２クラス画像分類に使うデータセットを読み込む関数を作成する。\n",
    "\n",
    "# 状況設定\n",
    "・クラスごとに別々のフォルダに画像が格納されている。ただ、クラス名の下にサブクラスフォルダがある2階層構造になっている。\n",
    "・フォルダ名がクラス名になっている\n",
    "・画像のファイル名は識別idになっている\n",
    "・画像のサイズは同じ\n",
    "・画像はRGBAの4チャネルカラー画像\n",
    "\n",
    "# フォルダ構成例\n",
    "images/class1/subclass1/1.png\n",
    "                        2.png\n",
    "                        3.png\n",
    "             /subclass2/1.png\n",
    "                        2.png\n",
    "                        3.png\n",
    "images/class2/subclass1/1.png\n",
    "                        2.png\n",
    "                        3.png\n",
    "             /subclass2/1.png\n",
    "                        2.png\n",
    "                        3.png\n",
    "# 処理の流れ\n",
    "・クラスごとに画像を読み込む。CNNで使用クラスにはサブクラスで識別せず、クラス名で識別する。\n",
    "・つまり、class1/subclass1/1.pngとclass1/subclass2/1.pngは同じクラスの画像として扱う。\n",
    "・画像を結合した後にシャッフルする。\n",
    "・画像の値を0~1に正規化する。\n",
    "・画像を訓練用とテスト用に分割する。\n",
    "・クラスごとにどの画像を訓練用に、どの画像をテスト用にしたかを記録する。\n",
    "・その際、画像名はクラスが違うと重複する。例えば、Class1/1.pngとClass2/1.pngは別の画像だが、画像名は同じである。\n",
    "・そのため、画像名の前にクラス名を付けて重複を回避する。\n",
    "・返り値は、train_dataとtest_dataの2つのリストである。\n",
    "・各返り値の構成は以下の通りである。\n",
    "    train_data = np.ndarray([(訓練用画像パス1、訓練用画像配列1、訓練用画像ラベル1),\n",
    "                                     (訓練用画像パス2、訓練用画像配列2、訓練用画像ラベル2),])\n",
    "    test_data = np.ndarray([(テスト用画像パス1、テスト用画像配列1、テスト用画像ラベル1),\n",
    "                                     (テスト用画像パス2、テスト用画像配列2、テスト用画像ラベル2),])\n",
    "\n",
    "# 以下に関数を定義していく。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowを使った２クラス画像分類CNNを作成する。\n",
    "その際、学習データが多い場合にそれらのデータを一度に全てGPUのメモリ上に乗せるのではなく、\n",
    "少しずつ読み込みながら学習を進めるにはTensorFlow, Kerasの何を使えばいいか？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(data_dir, train_ratio=0.8):\n",
    "    classes = os.listdir(data_dir)\n",
    "    num_classes = len(classes)\n",
    "    class_indices = {classes[i]: i for i in range(num_classes)}\n",
    "    train_data, test_data = [], []\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        subclass_dirs = os.listdir(class_dir)\n",
    "        for subclass_dir in subclass_dirs:\n",
    "            subclass_path = os.path.join(class_dir, subclass_dir)\n",
    "            image_files = os.listdir(subclass_path)\n",
    "            random.shuffle(image_files)\n",
    "            num_images = len(image_files)\n",
    "            num_train = int(num_images * train_ratio)\n",
    "            train_images = image_files[:num_train]\n",
    "            test_images = image_files[num_train:]\n",
    "            for image_file in train_images:\n",
    "                image_path = os.path.join(subclass_path, image_file)\n",
    "                image = Image.open(image_path).convert('RGBA')\n",
    "                image = np.array(image)\n",
    "                image = image / 255.0\n",
    "                train_data.append((image_path, image, class_indices[class_name]))\n",
    "            for image_file in test_images:\n",
    "                image_path = os.path.join(subclass_path, image_file)\n",
    "                image = Image.open(image_path).convert('RGBA')\n",
    "                image = np.array(image)\n",
    "                image = image / 255.0\n",
    "                test_data.append((image_path, image, class_indices[class_name]))\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(test_data)\n",
    "    train_data = [(f\"{classes[label]}/{os.path.basename(path)}\", image, label) for path, image, label in train_data]\n",
    "    test_data = [(f\"{classes[label]}/{os.path.basename(path)}\", image, label) for path, image, label in test_data]\n",
    "    return np.array(train_data), np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(r'Z:\\miyata\\RiverShapeRecognition_exp\\test\\output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 448, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNの実装\n",
    "\n",
    "２値分類を行うCNNを実装。入力は(504, 448, 4)の画像で0~1に正規化済み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "現在、河川流路形状の２値分類に対して、下のような２層の畳み込み層と、\n",
    "全結合層からなるCNNに訓練画像が3000枚、20エポックで制度が0.95ほど出ます。\n",
    "精度改善のために訓練画像を8000枚に増加させ、ネットワーク構造を変更してみようと思います。\n",
    "そこで、どのようなネットワーク構造にすればいいかを検討中です。\n",
    "一般に認識タスクで高い精度を誇るResNetのような構造も検討中ですが、行うタスクに対して\n",
    "必要以上に複雑なネットワーク構造を採用すると、過学習を起こす可能性があります。\n",
    "そのため、まずは、ネットワーク構造をシンプルにしたCNNを検討してみます。\n",
    "どのようなネットワーク構造をためしてみたらいいですか？\n",
    "\n",
    "# 現在のネットワーク構造\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 畳み込み層1  \n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(504, 448, 4)))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "\n",
    "# 畳み込み層2\n",
    "model.add(layers.Conv2D(64, kernel_size=3, activation='relu')) \n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "\n",
    "# 全結合層\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 畳み込み層1  \n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(504, 448, 4)))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "\n",
    "# 畳み込み層2\n",
    "model.add(layers.Conv2D(64, kernel_size=3, activation='relu')) \n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "\n",
    "# 全結合層\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# 出力層\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 502, 446, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 251, 223, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 249, 221, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 124, 110, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 872960)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               111739008 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,758,817\n",
      "Trainable params: 111,758,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 504, 448, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([train_data[i][1] for i in range(len(train_data))])\n",
    "y_train = np.array([train_data[i][2] for i in range(len(train_data))])\n",
    "X_test = np.array([test_data[i][1] for i in range(len(test_data))])\n",
    "y_test = np.array([test_data[i][2] for i in range(len(test_data))])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チェックポイントの作成\n",
    "# 検証セットで最高性能を達成したモデルを保存する\n",
    "# 保存先は./testmodel\n",
    "dirpath = \"./testmodel\"\n",
    "if not os.path.exists(dirpath):\n",
    "    os.mkdir(dirpath)\n",
    "filepath = os.path.join(dirpath, \"channelrecog.h5\")\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath, save_best_only=True)\n",
    "\n",
    "# 早期打ち切り\n",
    "# 10エポック連続で検証セットで性能が向上しなければ、学習を打ち切る\n",
    "ealystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, ealystopping_cb])\n",
    "\n",
    "# テストセットで性能を確認する\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "# 学習曲線をプロットする\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf291",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
